{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30533d1b",
   "metadata": {},
   "source": [
    " ## Importing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29a5291b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sqlalchemy import create_engine, text\n",
    "import plotly.express as px\n",
    "import csv\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import psycopg2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123ba43e",
   "metadata": {},
   "source": [
    "#### Data cleaning & Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39a9b592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Property_ID</th>\n",
       "      <th>Micro_Market</th>\n",
       "      <th>Project_Name</th>\n",
       "      <th>Developer_Name</th>\n",
       "      <th>Unit_Size_Sqft</th>\n",
       "      <th>Configuration</th>\n",
       "      <th>Ticket_Price_Cr</th>\n",
       "      <th>Transaction_Type</th>\n",
       "      <th>Buyer_Type</th>\n",
       "      <th>Purchase_Quarter</th>\n",
       "      <th>Connectivity_Score</th>\n",
       "      <th>Amenity_Score</th>\n",
       "      <th>Possession_Status</th>\n",
       "      <th>Sales_Channel</th>\n",
       "      <th>NRI_Buyer</th>\n",
       "      <th>Locality_Infra_Score</th>\n",
       "      <th>Avg_Traffic_Time_Min</th>\n",
       "      <th>Buyer_Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PROP000001</td>\n",
       "      <td>Sarjapur Road</td>\n",
       "      <td>Project_0</td>\n",
       "      <td>RMZ</td>\n",
       "      <td>4025.0</td>\n",
       "      <td>4bhk</td>\n",
       "      <td>12.750846039118798</td>\n",
       "      <td>Primary</td>\n",
       "      <td>NRI</td>\n",
       "      <td>2025-03-31</td>\n",
       "      <td>7.990091</td>\n",
       "      <td>5.462863</td>\n",
       "      <td>Launch</td>\n",
       "      <td>Broker</td>\n",
       "      <td>yes</td>\n",
       "      <td>9.212491</td>\n",
       "      <td>18</td>\n",
       "      <td>Loved the amenities!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PROP000002</td>\n",
       "      <td>Indiranagar</td>\n",
       "      <td>Project_1</td>\n",
       "      <td>Puravankara</td>\n",
       "      <td>5760.0</td>\n",
       "      <td>3Bhk</td>\n",
       "      <td>16.292151871065954</td>\n",
       "      <td>Primary</td>\n",
       "      <td>Other</td>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>4.839024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Under construction</td>\n",
       "      <td>NRI Desk</td>\n",
       "      <td>no</td>\n",
       "      <td>7.723898</td>\n",
       "      <td>106</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PROP000003</td>\n",
       "      <td>Bannerghatta Road</td>\n",
       "      <td>Project_2</td>\n",
       "      <td>Tata Housing</td>\n",
       "      <td>7707.0</td>\n",
       "      <td>4bhk</td>\n",
       "      <td>10.517724412961911</td>\n",
       "      <td>Primary</td>\n",
       "      <td>HNI</td>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>8.131315</td>\n",
       "      <td>8.669227</td>\n",
       "      <td>Ready to move</td>\n",
       "      <td>Direct</td>\n",
       "      <td>yes</td>\n",
       "      <td>6.985493</td>\n",
       "      <td>113</td>\n",
       "      <td>Agent was not responsive.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PROP000004</td>\n",
       "      <td>bellary road</td>\n",
       "      <td>Project_3</td>\n",
       "      <td>Embassy</td>\n",
       "      <td>6192.0</td>\n",
       "      <td>3BHK</td>\n",
       "      <td>9.396367494232896</td>\n",
       "      <td>Primary</td>\n",
       "      <td>HNI</td>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>7.501657</td>\n",
       "      <td>5.720246</td>\n",
       "      <td>Ready to move</td>\n",
       "      <td>Online</td>\n",
       "      <td>yes</td>\n",
       "      <td>6.100929</td>\n",
       "      <td>106</td>\n",
       "      <td>Excellent location!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PROP000005</td>\n",
       "      <td>Koramangala</td>\n",
       "      <td>Project_4</td>\n",
       "      <td>SNN Raj</td>\n",
       "      <td>7147.0</td>\n",
       "      <td>4Bhk</td>\n",
       "      <td>15.345392444511946</td>\n",
       "      <td>Secondary</td>\n",
       "      <td>HNI</td>\n",
       "      <td>2024-12-31</td>\n",
       "      <td>4.525216</td>\n",
       "      <td>8.609649</td>\n",
       "      <td>Under construction</td>\n",
       "      <td>Broker</td>\n",
       "      <td>no</td>\n",
       "      <td>5.312510</td>\n",
       "      <td>18</td>\n",
       "      <td>Too far from my office.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Property_ID       Micro_Market Project_Name Developer_Name  Unit_Size_Sqft  \\\n",
       "0  PROP000001      Sarjapur Road    Project_0            RMZ          4025.0   \n",
       "1  PROP000002        Indiranagar    Project_1    Puravankara          5760.0   \n",
       "2  PROP000003  Bannerghatta Road    Project_2   Tata Housing          7707.0   \n",
       "3  PROP000004       bellary road    Project_3        Embassy          6192.0   \n",
       "4  PROP000005        Koramangala    Project_4        SNN Raj          7147.0   \n",
       "\n",
       "  Configuration     Ticket_Price_Cr Transaction_Type Buyer_Type  \\\n",
       "0          4bhk  12.750846039118798          Primary        NRI   \n",
       "1          3Bhk  16.292151871065954          Primary      Other   \n",
       "2          4bhk  10.517724412961911          Primary        HNI   \n",
       "3          3BHK   9.396367494232896          Primary        HNI   \n",
       "4          4Bhk  15.345392444511946        Secondary        HNI   \n",
       "\n",
       "  Purchase_Quarter  Connectivity_Score  Amenity_Score   Possession_Status  \\\n",
       "0       2025-03-31            7.990091       5.462863              Launch   \n",
       "1       2024-06-30            4.839024            NaN  Under construction   \n",
       "2       2023-12-31            8.131315       8.669227       Ready to move   \n",
       "3       2024-03-31            7.501657       5.720246       Ready to move   \n",
       "4       2024-12-31            4.525216       8.609649  Under construction   \n",
       "\n",
       "  Sales_Channel NRI_Buyer  Locality_Infra_Score  Avg_Traffic_Time_Min  \\\n",
       "0        Broker       yes              9.212491                    18   \n",
       "1      NRI Desk        no              7.723898                   106   \n",
       "2        Direct       yes              6.985493                   113   \n",
       "3        Online       yes              6.100929                   106   \n",
       "4        Broker        no              5.312510                    18   \n",
       "\n",
       "              Buyer_Comments  \n",
       "0       Loved the amenities!  \n",
       "1                        NaN  \n",
       "2  Agent was not responsive.  \n",
       "3        Excellent location!  \n",
       "4    Too far from my office.  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luxury_housing_df = pd.read_csv(r\"C:\\Users\\sathishkumar\\Downloads\\Luxury_housing_sales_analysis\\Data\\Luxury_Housing_Bangalore.csv\")\n",
    "luxury_housing_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be513bb",
   "metadata": {},
   "source": [
    "##### Data inspecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3562a152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101000 entries, 0 to 100999\n",
      "Data columns (total 18 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   Property_ID           101000 non-null  object \n",
      " 1   Micro_Market          101000 non-null  object \n",
      " 2   Project_Name          101000 non-null  object \n",
      " 3   Developer_Name        101000 non-null  object \n",
      " 4   Unit_Size_Sqft        90954 non-null   float64\n",
      " 5   Configuration         101000 non-null  object \n",
      " 6   Ticket_Price_Cr       90981 non-null   object \n",
      " 7   Transaction_Type      101000 non-null  object \n",
      " 8   Buyer_Type            101000 non-null  object \n",
      " 9   Purchase_Quarter      101000 non-null  object \n",
      " 10  Connectivity_Score    101000 non-null  float64\n",
      " 11  Amenity_Score         90910 non-null   float64\n",
      " 12  Possession_Status     101000 non-null  object \n",
      " 13  Sales_Channel         101000 non-null  object \n",
      " 14  NRI_Buyer             101000 non-null  object \n",
      " 15  Locality_Infra_Score  101000 non-null  float64\n",
      " 16  Avg_Traffic_Time_Min  101000 non-null  int64  \n",
      " 17  Buyer_Comments        82713 non-null   object \n",
      "dtypes: float64(4), int64(1), object(13)\n",
      "memory usage: 13.9+ MB\n"
     ]
    }
   ],
   "source": [
    "luxury_housing_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8d3e068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101000, 18)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luxury_housing_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf5f7eb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unit_Size_Sqft</th>\n",
       "      <th>Connectivity_Score</th>\n",
       "      <th>Amenity_Score</th>\n",
       "      <th>Locality_Infra_Score</th>\n",
       "      <th>Avg_Traffic_Time_Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>90954.000000</td>\n",
       "      <td>101000.000000</td>\n",
       "      <td>90910.000000</td>\n",
       "      <td>101000.000000</td>\n",
       "      <td>101000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5972.274765</td>\n",
       "      <td>6.992619</td>\n",
       "      <td>7.503663</td>\n",
       "      <td>7.498426</td>\n",
       "      <td>67.182921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1783.397836</td>\n",
       "      <td>1.731757</td>\n",
       "      <td>1.440758</td>\n",
       "      <td>1.443128</td>\n",
       "      <td>30.271611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>4.000031</td>\n",
       "      <td>5.000224</td>\n",
       "      <td>5.000013</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4477.250000</td>\n",
       "      <td>5.494526</td>\n",
       "      <td>6.260329</td>\n",
       "      <td>6.247954</td>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5990.000000</td>\n",
       "      <td>6.985805</td>\n",
       "      <td>7.499123</td>\n",
       "      <td>7.495614</td>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7497.000000</td>\n",
       "      <td>8.490000</td>\n",
       "      <td>8.752207</td>\n",
       "      <td>8.749824</td>\n",
       "      <td>93.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8999.000000</td>\n",
       "      <td>9.999970</td>\n",
       "      <td>9.999865</td>\n",
       "      <td>9.999956</td>\n",
       "      <td>119.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unit_Size_Sqft  Connectivity_Score  Amenity_Score  \\\n",
       "count    90954.000000       101000.000000   90910.000000   \n",
       "mean      5972.274765            6.992619       7.503663   \n",
       "std       1783.397836            1.731757       1.440758   \n",
       "min         -1.000000            4.000031       5.000224   \n",
       "25%       4477.250000            5.494526       6.260329   \n",
       "50%       5990.000000            6.985805       7.499123   \n",
       "75%       7497.000000            8.490000       8.752207   \n",
       "max       8999.000000            9.999970       9.999865   \n",
       "\n",
       "       Locality_Infra_Score  Avg_Traffic_Time_Min  \n",
       "count         101000.000000         101000.000000  \n",
       "mean               7.498426             67.182921  \n",
       "std                1.443128             30.271611  \n",
       "min                5.000013             15.000000  \n",
       "25%                6.247954             41.000000  \n",
       "50%                7.495614             67.000000  \n",
       "75%                8.749824             93.000000  \n",
       "max                9.999956            119.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luxury_housing_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7944000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Property_ID              object\n",
       "Micro_Market             object\n",
       "Project_Name             object\n",
       "Developer_Name           object\n",
       "Unit_Size_Sqft          float64\n",
       "Configuration            object\n",
       "Ticket_Price_Cr          object\n",
       "Transaction_Type         object\n",
       "Buyer_Type               object\n",
       "Purchase_Quarter         object\n",
       "Connectivity_Score      float64\n",
       "Amenity_Score           float64\n",
       "Possession_Status        object\n",
       "Sales_Channel            object\n",
       "NRI_Buyer                object\n",
       "Locality_Infra_Score    float64\n",
       "Avg_Traffic_Time_Min      int64\n",
       "Buyer_Comments           object\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luxury_housing_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc5a8385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1000)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luxury_housing_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "676a8a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Property_ID                 0\n",
       "Micro_Market                0\n",
       "Project_Name                0\n",
       "Developer_Name              0\n",
       "Unit_Size_Sqft          10046\n",
       "Configuration               0\n",
       "Ticket_Price_Cr         10019\n",
       "Transaction_Type            0\n",
       "Buyer_Type                  0\n",
       "Purchase_Quarter            0\n",
       "Connectivity_Score          0\n",
       "Amenity_Score           10090\n",
       "Possession_Status           0\n",
       "Sales_Channel               0\n",
       "NRI_Buyer                   0\n",
       "Locality_Infra_Score        0\n",
       "Avg_Traffic_Time_Min        0\n",
       "Buyer_Comments          18287\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luxury_housing_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189667ef",
   "metadata": {},
   "source": [
    "##### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4be39fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dataset\n",
    "def load_data(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load raw CSV data.\"\"\"\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6ec5cc",
   "metadata": {},
   "source": [
    "##### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "071d1322",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop duplicates\n",
    "def drop_duplicates(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Remove duplicate rows and report how many were dropped.\"\"\"\n",
    "    before = df.shape[0]   # number of rows before\n",
    "    df = df.drop_duplicates()\n",
    "    after = df.shape[0]    # number of rows after\n",
    "    print(f\"Dropped {before - after} duplicate rows.\")\n",
    "    return df\n",
    "\n",
    "#Type conversion\n",
    "def convert_types(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Convert necessary columns to proper dtypes.\"\"\"\n",
    "    df['Purchase_Quarter'] = pd.to_datetime(df['Purchase_Quarter'], errors='coerce')\n",
    "    df['Ticket_Price_Cr'] = pd.to_numeric(df['Ticket_Price_Cr'], errors='coerce')\n",
    "    return df\n",
    "\n",
    "#Normalization\n",
    "def normalize_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Normalize column names and key fields.\"\"\"\n",
    "    # Strip whitespace from column names\n",
    "    df.columns = df.columns.str.strip()\n",
    "    # Clean up Ticket_Price_Cr\n",
    "    df['Ticket_Price_Cr'] = (\n",
    "        df['Ticket_Price_Cr']\n",
    "        .astype(str)\n",
    "        .str.replace(\"â‚¹\", \"\", regex=False)\n",
    "        .str.replace(\"Cr\", \"\", regex=False)\n",
    "        .str.replace(\",\", \"\", regex=False)\n",
    "        .str.strip()\n",
    "        .astype(float)\n",
    "    )\n",
    "    # Normalize categorical text fields\n",
    "    text_cols = [\n",
    "        \"Micro_Market\", \"Project_Name\", \"Developer_Name\",\n",
    "        \"Configuration\", \"Transaction_Type\", \"Buyer_Type\",\n",
    "        \"Purchase_Quarter\", \"Possession_Status\", \"Sales_Channel\",\n",
    "        \"Buyer_Comments\", \"NRI_Buyer\"\n",
    "    ]\n",
    "    for col in text_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str).str.strip().str.title()\n",
    "    return df\n",
    "\n",
    "# converting -1 values to positive values\n",
    "def absolute_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Convert possible negative numbers to absolute.\"\"\"\n",
    "    for col in ['Unit_Size_Sqft', 'Ticket_Price_Cr']:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].abs()\n",
    "    return df\n",
    "\n",
    "#Handling missing values\n",
    "def handle_missing_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Fill and handle missing values for numeric and categorical columns.\"\"\"\n",
    "    print(\" Handling missing values...\")\n",
    "\n",
    "    # Step 1: Define numeric columns explicitly\n",
    "    numeric_cols = [\"Unit_Size_Sqft\", \"Ticket_Price_Cr\", \"Amenity_Score\"]\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            # Convert to numeric safely (ignore non-numeric values)\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            median_value = df[col].median(skipna=True)\n",
    "            df[col] = df[col].fillna(median_value)\n",
    "            print(f\" Filled missing values in numeric column '{col}' with median = {median_value}\")\n",
    "\n",
    "    # Step 2: Handle Buyer_Comments separately\n",
    "    if \"Buyer_Comments\" in df.columns:\n",
    "        df[\"Buyer_Comments\"] = df[\"Buyer_Comments\"].replace([\"Nan\", \"nan\", \"NaN\"], np.nan)\n",
    "        df[\"Buyer_Comments\"] = df[\"Buyer_Comments\"].fillna(\"No Comments Provided\")\n",
    "        print(\"Filled missing Buyer_Comments with 'No Comments Provided'\")\n",
    "\n",
    "    # Step 3: General categorical fill (for other text columns if any)\n",
    "    for col in df.select_dtypes(include=\"object\").columns:\n",
    "        if col != \"Buyer_Comments\":  # Already handled\n",
    "            mode_value = df[col].mode()[0]\n",
    "            df[col] = df[col].fillna(mode_value)\n",
    "            print(f\" Filled missing values in categorical column '{col}' with mode = {mode_value}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856b819c",
   "metadata": {},
   "source": [
    "##### Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0032570a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Column transformation\n",
    "def derive_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Add derived/feature columns.\"\"\"\n",
    "    # Price per Sqft\n",
    "    df['Price_per_Sqft'] = (df['Ticket_Price_Cr'] * 1e7) / df['Unit_Size_Sqft']\n",
    "    # Reconvert date if needed and extract quarter/year\n",
    "    df['Purchase_Quarter'] = pd.to_datetime(df['Purchase_Quarter'], errors='coerce')\n",
    "    df['Quarter_Number'] = df['Purchase_Quarter'].dt.quarter\n",
    "    df['Year'] = df['Purchase_Quarter'].dt.year\n",
    "    # Booking Flag\n",
    "    df['Booking_Flag'] = df['Transaction_Type'].apply(lambda x: 1 if str(x).lower() == \"primary\" else 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fae2fdc",
   "metadata": {},
   "source": [
    "##### Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91c1ea21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Make plots appear inline\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Load Dataset\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\sathishkumar\\Downloads\\Luxury_Housing_Bangalore.csv\")\n",
    "\n",
    "# EDA Function\n",
    "def eda_plots(df):\n",
    "    print(\"===== Univariate Analysis =====\")\n",
    "    # Numeric columns\n",
    "    numeric_cols = ['Ticket_Price_Cr','Unit_Size_Sqft','Price_per_Sqft']\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            plt.figure(figsize=(8,4))\n",
    "            sns.histplot(df[col], bins=50, kde=True)\n",
    "            plt.title(f\"Distribution of {col}\")\n",
    "            plt.show()\n",
    "    \n",
    "    # Categorical columns\n",
    "    cat_cols = ['Transaction_Type','Buyer_Type','Configuration','Possession_Status','Sales_Channel']\n",
    "    for col in cat_cols:\n",
    "        if col in df.columns:\n",
    "            plt.figure(figsize=(8,4))\n",
    "            df[col].value_counts(normalize=True).plot(kind='bar', color='skyblue')\n",
    "            plt.title(f\"Distribution of {col}\")\n",
    "            plt.ylabel(\"Proportion\")\n",
    "            plt.show()\n",
    "    \n",
    "    print(\"===== Bivariate Analysis =====\")\n",
    "    # Scatter plots for numeric vs numeric\n",
    "    if 'Unit_Size_Sqft' in df.columns and 'Ticket_Price_Cr' in df.columns:\n",
    "        plt.figure(figsize=(8,5))\n",
    "        sns.scatterplot(x='Unit_Size_Sqft', y='Ticket_Price_Cr', data=df, hue='Transaction_Type')\n",
    "        plt.title(\"Ticket Price vs Unit Size by Transaction Type\")\n",
    "        plt.show()\n",
    "    \n",
    "    # Boxplot: Price per sqft by Micro Market\n",
    "    if 'Micro_Market' in df.columns and 'Price_per_Sqft' in df.columns:\n",
    "        top_markets = df['Micro_Market'].value_counts().head(10).index\n",
    "        plt.figure(figsize=(10,5))\n",
    "        sns.boxplot(\n",
    "            x='Micro_Market',\n",
    "            y='Price_per_Sqft',\n",
    "            data=df[df['Micro_Market'].isin(top_markets)]\n",
    "        )\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.title(\"Price per Sqft across Top 10 Micro Markets\")\n",
    "        plt.show()\n",
    "    \n",
    "    # Quarterly trend\n",
    "    if {'Year','Quarter_Number','Ticket_Price_Cr'}.issubset(df.columns):\n",
    "        quarterly_price = df.groupby(['Year','Quarter_Number'])['Ticket_Price_Cr'].mean().reset_index()\n",
    "        plt.figure(figsize=(10,5))\n",
    "        sns.lineplot(x='Quarter_Number', y='Ticket_Price_Cr', hue='Year', data=quarterly_price, marker='o')\n",
    "        plt.title(\"Average Ticket Price per Quarter\")\n",
    "        plt.show()\n",
    "    \n",
    "    print(\"===== Multivariate Analysis =====\")\n",
    "    cols = ['Ticket_Price_Cr','Unit_Size_Sqft','Price_per_Sqft','Quarter_Number','Booking_Flag']\n",
    "    available = [c for c in cols if c in df.columns]\n",
    "    if len(available) > 1:\n",
    "        plt.figure(figsize=(8,6))\n",
    "        sns.heatmap(df[available].corr(), annot=True, cmap=\"coolwarm\")\n",
    "        plt.title(\"Correlation Heatmap\")\n",
    "        plt.show()\n",
    "    print(\"EDA complete.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de50743",
   "metadata": {},
   "source": [
    "##### Saving cleaned datas into cleaned csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4c20273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving cleaned data\n",
    "def save_clean_csv(df: pd.DataFrame, output_path: str):\n",
    "    \"\"\"Save cleaned DataFrame to CSV.\"\"\"\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\" Cleaned data saved as {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca6f38a",
   "metadata": {},
   "source": [
    "##### Uploading datas into postgresql database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5bb616b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data uploaded successfully to public.luxury_housing\n"
     ]
    }
   ],
   "source": [
    "# Define the function FIRST\n",
    "def upload_to_database(df: pd.DataFrame, table_name: str, db_url: str, schema: str = \"public\"):\n",
    "    \"\"\"\n",
    "    Upload DataFrame to PostgreSQL database.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create SQLAlchemy engine\n",
    "        engine = create_engine(db_url)\n",
    "        \n",
    "        # Upload DataFrame\n",
    "        df.to_sql(table_name, engine, schema=schema, if_exists=\"replace\", index=False)\n",
    "        \n",
    "        print(f\" Data uploaded successfully to {schema}.{table_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\" Database upload failed: {e}\")\n",
    "\n",
    "# Load your CSV\n",
    "df = pd.read_csv(r\"C:\\Users\\sathishkumar\\Downloads\\Luxury_Housing_Bangalore.csv\")\n",
    "df.head()\n",
    "\n",
    "#  Define DB URL\n",
    "db_url = \"postgresql+psycopg2://postgres:MALATHI28@localhost:5432/luxury_housingdb\"\n",
    "\n",
    "#  Call the function\n",
    "upload_to_database(df, \"luxury_housing\", db_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7edf9775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1000 duplicate rows.\n",
      " Handling missing values...\n",
      " Filled missing values in numeric column 'Unit_Size_Sqft' with median = 5990.0\n",
      " Filled missing values in numeric column 'Ticket_Price_Cr' with median = 12.035263970516692\n",
      " Filled missing values in numeric column 'Amenity_Score' with median = 7.49976649202713\n",
      "Filled missing Buyer_Comments with 'No Comments Provided'\n",
      " Filled missing values in categorical column 'Property_ID' with mode = PROP000001\n",
      " Filled missing values in categorical column 'Micro_Market' with mode = Jayanagar\n",
      " Filled missing values in categorical column 'Project_Name' with mode = Project_0\n",
      " Filled missing values in categorical column 'Developer_Name' with mode = Prestige\n",
      " Filled missing values in categorical column 'Configuration' with mode = 5Bhk+\n",
      " Filled missing values in categorical column 'Transaction_Type' with mode = Primary\n",
      " Filled missing values in categorical column 'Buyer_Type' with mode = Cxo\n",
      " Filled missing values in categorical column 'Purchase_Quarter' with mode = 2024-03-31\n",
      " Filled missing values in categorical column 'Possession_Status' with mode = Under Construction\n",
      " Filled missing values in categorical column 'Sales_Channel' with mode = Online\n",
      " Filled missing values in categorical column 'NRI_Buyer' with mode = No\n",
      " Cleaned data saved as C:\\Users\\sathishkumar\\Downloads\\Luxury_Housing_Cleaned.csv\n",
      " Data uploaded successfully to public.luxury_housing\n"
     ]
    }
   ],
   "source": [
    "# Apply cleaning pipeline\n",
    "df = load_data(r\"C:\\Users\\sathishkumar\\Downloads\\Luxury_Housing_Bangalore.csv\")\n",
    "df = drop_duplicates(df)\n",
    "df = convert_types(df)\n",
    "df = normalize_columns(df)\n",
    "df = absolute_values(df)\n",
    "df = handle_missing_values(df)\n",
    "df = derive_columns(df)\n",
    "\n",
    "# Save cleaned data (optional)\n",
    "save_clean_csv(df, r\"C:\\Users\\sathishkumar\\Downloads\\Luxury_Housing_Cleaned.csv\")\n",
    "\n",
    "# Upload cleaned data to PostgreSQL\n",
    "from sqlalchemy import create_engine\n",
    "upload_to_database(df, \"luxury_housing\", db_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b0be3ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize text columns\n",
    "df['Micro_Market'] = df['Micro_Market'].str.title().str.strip()\n",
    "df['Developer_Name'] = df['Developer_Name'].str.title().str.strip()\n",
    "df['Configuration'] = df['Configuration'].str.upper().str.replace('+', 'PLUS', regex=False)\n",
    "df['Possession_Status'] = df['Possession_Status'].str.title().str.strip()\n",
    "df['Sales_Channel'] = df['Sales_Channel'].str.title().str.strip()\n",
    "df['Buyer_Type'] = df['Buyer_Type'].str.upper().str.strip()  # NRI, HNI, CXO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
